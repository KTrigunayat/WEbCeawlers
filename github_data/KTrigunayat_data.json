{
    "profile": {
        "login": "KTrigunayat",
        "id": 149764145,
        "node_id": "U_kgDOCO04MQ",
        "avatar_url": "https://avatars.githubusercontent.com/u/149764145?v=4",
        "gravatar_id": "",
        "url": "https://api.github.com/users/KTrigunayat",
        "html_url": "https://github.com/KTrigunayat",
        "followers_url": "https://api.github.com/users/KTrigunayat/followers",
        "following_url": "https://api.github.com/users/KTrigunayat/following{/other_user}",
        "gists_url": "https://api.github.com/users/KTrigunayat/gists{/gist_id}",
        "starred_url": "https://api.github.com/users/KTrigunayat/starred{/owner}{/repo}",
        "subscriptions_url": "https://api.github.com/users/KTrigunayat/subscriptions",
        "organizations_url": "https://api.github.com/users/KTrigunayat/orgs",
        "repos_url": "https://api.github.com/users/KTrigunayat/repos",
        "events_url": "https://api.github.com/users/KTrigunayat/events{/privacy}",
        "received_events_url": "https://api.github.com/users/KTrigunayat/received_events",
        "type": "User",
        "user_view_type": "private",
        "site_admin": false,
        "name": "Kshitiz Trigunayat",
        "company": null,
        "blog": "",
        "location": null,
        "email": null,
        "hireable": null,
        "bio": "Founder - Planiva\r\nData Science Intern at Zordie AI",
        "twitter_username": null,
        "public_repos": 13,
        "public_gists": 0,
        "followers": 0,
        "following": 0,
        "created_at": "2023-11-03T07:21:22Z",
        "updated_at": "2025-05-06T16:05:03Z",
        "private_gists": 0,
        "total_private_repos": 1,
        "owned_private_repos": 1,
        "disk_usage": 15185,
        "collaborators": 0,
        "two_factor_authentication": false,
        "plan": {
            "name": "free",
            "space": 976562499,
            "collaborators": 0,
            "private_repos": 10000
        }
    },
    "repositories": [
        {
            "id": 957877313,
            "name": "Still-Travelling-Internship",
            "full_name": "KTrigunayat/Still-Travelling-Internship",
            "html_url": "https://github.com/KTrigunayat/Still-Travelling-Internship",
            "description": null,
            "fork": false,
            "created_at": "2025-03-31T09:34:17Z",
            "updated_at": "2025-03-31T09:34:21Z",
            "pushed_at": "2025-03-31T09:34:18Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": null,
            "open_issues_count": 0,
            "license": null,
            "topics": [],
            "languages": {},
            "commits": [
                {
                    "sha": "ad235dd1a01839a6ac89791b3c8883c613ad80ab",
                    "message": "Initial commit",
                    "author_name": "KTrigunayat",
                    "author_date": "2025-03-31T09:34:18Z",
                    "committer_name": "GitHub",
                    "committer_date": "2025-03-31T09:34:18Z",
                    "html_url": "https://github.com/KTrigunayat/Still-Travelling-Internship/commit/ad235dd1a01839a6ac89791b3c8883c613ad80ab"
                }
            ],
            "readme_content": "# Still-Travelling-Internship",
            "file_contents": {
                "README.md": "# Still-Travelling-Internship"
            }
        },
        {
            "id": 940387158,
            "name": "AI-Powered-Disaster-Relief-Supply-Demand-Forecast",
            "full_name": "KTrigunayat/AI-Powered-Disaster-Relief-Supply-Demand-Forecast",
            "html_url": "https://github.com/KTrigunayat/AI-Powered-Disaster-Relief-Supply-Demand-Forecast",
            "description": "Develop a machine learning model that forecasts the demand for disaster relief supplies using historical disaster data from the EM-DAT database.",
            "fork": false,
            "created_at": "2025-02-28T04:50:00Z",
            "updated_at": "2025-03-23T02:08:02Z",
            "pushed_at": "2025-03-01T05:26:15Z",
            "stargazers_count": 1,
            "watchers_count": 1,
            "forks_count": 0,
            "language": "Python",
            "open_issues_count": 0,
            "license": null,
            "topics": [],
            "languages": {
                "Python": 5228
            },
            "commits": [
                {
                    "sha": "5d564835aa3fc49f4da901446e0ba2b7d62fd647",
                    "message": "Initial Commit",
                    "author_name": "Kshitiz Trigunayat",
                    "author_date": "2025-03-01T05:26:09Z",
                    "committer_name": "Kshitiz Trigunayat",
                    "committer_date": "2025-03-01T05:26:09Z",
                    "html_url": "https://github.com/KTrigunayat/AI-Powered-Disaster-Relief-Supply-Demand-Forecast/commit/5d564835aa3fc49f4da901446e0ba2b7d62fd647"
                },
                {
                    "sha": "4a8a3ac8a20ef62076a08923a3f3f2843692374b",
                    "message": "Initial commit",
                    "author_name": "KTrigunayat",
                    "author_date": "2025-02-28T04:50:00Z",
                    "committer_name": "GitHub",
                    "committer_date": "2025-02-28T04:50:00Z",
                    "html_url": "https://github.com/KTrigunayat/AI-Powered-Disaster-Relief-Supply-Demand-Forecast/commit/4a8a3ac8a20ef62076a08923a3f3f2843692374b"
                }
            ],
            "readme_content": "# AI-Powered-Disaster-Relief-Supply-Demand-Forecast\nDevelop a machine learning model that forecasts the demand for disaster relief supplies using historical disaster data from the EM-DAT database.\n",
            "file_contents": {
                "DataPreprocessing.py": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA, TruncatedSVD\n\n# Step 1: Load the dataset with error handling for encoding issues\ntry:\n    data = pd.read_csv('Dataset.csv', encoding='utf-8')\n    print(\"File loaded successfully with UTF-8 encoding.\")\nexcept UnicodeDecodeError:\n    data = pd.read_csv('Dataset.csv', encoding='latin1')\n    print(\"File loaded successfully with Latin-1 encoding.\")\n\n# Display basic dataset info\nprint(\"\\nDataset Shape:\", data.shape)\nprint(\"Columns Available:\", data.columns)\n\n# Step 2: Convert date columns to datetime format (if applicable)\ndate_columns = ['Start Date', 'End Date']  # Adjust column names as needed\nfor col in date_columns:\n    if col in data.columns:\n        data[col] = pd.to_datetime(data[col], errors='coerce')\n\n# Step 3: Handle missing values\nprint(\"\\nMissing Values Before Cleaning:\")\nprint(data.isnull().sum())\n\n# Fill missing numerical values with median\nnum_cols = data.select_dtypes(include=['int64', 'float64']).columns\nfor col in num_cols:\n    data[col].fillna(data[col].median(), inplace=True)\n\n# Fill missing categorical values with mode\ncat_cols = data.select_dtypes(include=['object']).columns\nfor col in cat_cols:\n    data[col].fillna(data[col].mode()[0], inplace=True)\n\n# Step 4: Remove duplicate records\ndata.drop_duplicates(inplace=True)\n\n# Step 5: Feature Engineering\n# Create a 'Severity Index' as a combination of key impact factors\nif {'Total Deaths','No. Injured','No. Affected','No. Homeless','Total Affected',\"Total Damage ('000 US$)\"}.issubset(data.columns):#Total Deaths,No. Injured,No. Affected,No. Homeless,Total Affected,Total Damage ('000 US$)\n    data['Severity_Index'] = (\n        data['Total Deaths'] * 0.5 + data['Total Damage ($USD)'] * 0.2 + data['No. Injured'] * 0.1 + data['No. Affected'] * 0.1 + data['No. Homeless'] * 0.1\n    )\n\n# Extract year from start date (if applicable)\nif 'Start Date' in data.columns:\n    data['Year'] = data['Start Date'].dt.year\n\n# One-Hot Encode categorical variables (e.g., Disaster Type)\nif 'Disaster Type' in data.columns:\n    data = pd.get_dummies(data, columns=['Disaster Type'], drop_first=True)\n\n# Step 6: Feature Scaling using StandardScaler\nscaler = StandardScaler()\nscaled_cols = num_cols.tolist()  # Convert column index to list\nif 'Severity_Index' in data.columns:\n    scaled_cols.append('Severity_Index')  # Include engineered feature\n\ndata[scaled_cols] = scaler.fit_transform(data[scaled_cols])\n\n# Step 7: Dimensionality Reduction using PCA & SVD\npca = PCA(n_components=5)  # Adjust components based on variance analysis\ndata_pca = pca.fit_transform(data[scaled_cols])\nprint(\"\\nExplained Variance by PCA Components:\", pca.explained_variance_ratio_)\n\nsvd = TruncatedSVD(n_components=5)\ndata_svd = svd.fit_transform(data[scaled_cols])\n\n# Step 8: Save the cleaned dataset\ndata.to_csv('emdat_preprocessed.csv', index=False)\nprint(\"\\nData Preprocessing Completed! File Saved as 'emdat_preprocessed.csv'.\")\n",
                "EDA.py": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\nfrom scipy.stats import skew, kurtosis\n\n# Load the preprocessed dataset\ndata = pd.read_csv('emdat_preprocessed.csv')\n\n# Set visualization style\nsns.set_style(\"darkgrid\")\n\n# Step 1: Basic Dataset Overview\nprint(\"\\nDataset Shape:\", data.shape)\nprint(\"\\nColumn Data Types:\\n\", data.dtypes)\nprint(\"\\nFirst 5 Rows:\\n\", data.head())\n\n# Step 2: Check for Missing Values\nprint(\"\\nMissing Values Per Column:\\n\", data.isnull().sum())\n\n# Visualize missing values using a heatmap\nplt.figure(figsize=(12, 5))\nmsno.heatmap(data)\nplt.title(\"Missing Values Heatmap\")\nplt.show()\n\n# Step 3: Summary Statistics\nprint(\"\\nSummary Statistics:\\n\", data.describe())\n\n# Step 4: Detect Outliers using Box Plots\nplt.figure(figsize=(15, 6))\nsns.boxplot(data=data.select_dtypes(include=['int64', 'float64']))\nplt.xticks(rotation=90)\nplt.title(\"Box Plot of Numerical Features (Outlier Detection)\")\nplt.show()\n\n# Step 5: Skewness & Kurtosis Analysis\nskewness = data.skew()\nkurt = data.kurtosis()\nprint(\"\\nFeature Skewness:\\n\", skewness)\nprint(\"\\nFeature Kurtosis:\\n\", kurt)\n\n# Step 6: Correlation Analysis\ncorr_matrix = data.corr()\n\n# Display correlation heatmap\nplt.figure(figsize=(12, 6))\nsns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()\n\n# Step 7: Distribution of Key Features\nnum_cols = data.select_dtypes(include=['int64', 'float64']).columns\n\nplt.figure(figsize=(15, 10))\nfor i, col in enumerate(num_cols[:6]):  # Plot only first 6 numerical features for clarity\n    plt.subplot(2, 3, i + 1)\n    sns.histplot(data[col], kde=True, bins=30)\n    plt.title(f'Distribution of {col}')\nplt.tight_layout()\nplt.show()\n\n# Step 8: Relationship Between Disaster Type and Severity Index (if exists)\nif 'Severity_Index' in data.columns:\n    plt.figure(figsize=(12, 6))\n    sns.boxplot(x='Disaster Type_Flood', y='Severity_Index', data=data)\n    plt.title(\"Impact of Disaster Type on Severity Index\")\n    plt.xticks(rotation=45)\n    plt.show()\n\nprint(\"\\nEDA Completed! Check the visualizations.\")\n",
                "README.md": "# AI-Powered-Disaster-Relief-Supply-Demand-Forecast\nDevelop a machine learning model that forecasts the demand for disaster relief supplies using historical disaster data from the EM-DAT database.\n"
            }
        },
        {
            "id": 951053703,
            "name": "Akaike-Internship-Assignment",
            "full_name": "KTrigunayat/Akaike-Internship-Assignment",
            "html_url": "https://github.com/KTrigunayat/Akaike-Internship-Assignment",
            "description": "This repository hold everything related to the Akaike Internship Assignment",
            "fork": false,
            "created_at": "2025-03-19T05:08:35Z",
            "updated_at": "2025-03-19T05:08:39Z",
            "pushed_at": "2025-03-19T05:08:35Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": null,
            "open_issues_count": 0,
            "license": null,
            "topics": [],
            "languages": {},
            "commits": [
                {
                    "sha": "c215f7e17cbec5a81b5a6e59f2b42070460ce53b",
                    "message": "Initial commit",
                    "author_name": "KTrigunayat",
                    "author_date": "2025-03-19T05:08:35Z",
                    "committer_name": "GitHub",
                    "committer_date": "2025-03-19T05:08:35Z",
                    "html_url": "https://github.com/KTrigunayat/Akaike-Internship-Assignment/commit/c215f7e17cbec5a81b5a6e59f2b42070460ce53b"
                }
            ],
            "readme_content": "# Akaike-Internship-Assignment\nThis repository hold everything related to the Akaike Internship Assignment\n",
            "file_contents": {
                "README.md": "# Akaike-Internship-Assignment\nThis repository hold everything related to the Akaike Internship Assignment\n"
            }
        },
        {
            "id": 933616655,
            "name": "Portfolio",
            "full_name": "KTrigunayat/Portfolio",
            "html_url": "https://github.com/KTrigunayat/Portfolio",
            "description": null,
            "fork": false,
            "created_at": "2025-02-16T11:19:08Z",
            "updated_at": "2025-02-16T11:19:08Z",
            "pushed_at": "2025-02-16T11:19:08Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": null,
            "open_issues_count": 0,
            "license": null,
            "topics": [],
            "languages": {},
            "commits": [],
            "readme_content": null,
            "file_contents": {}
        },
        {
            "id": 928095489,
            "name": "Skin-Cancer-Detection-using-CNN",
            "full_name": "KTrigunayat/Skin-Cancer-Detection-using-CNN",
            "html_url": "https://github.com/KTrigunayat/Skin-Cancer-Detection-using-CNN",
            "description": null,
            "fork": false,
            "created_at": "2025-02-06T03:45:14Z",
            "updated_at": "2025-02-06T03:45:15Z",
            "pushed_at": "2025-02-06T03:45:15Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": null,
            "open_issues_count": 0,
            "license": null,
            "topics": [],
            "languages": {},
            "commits": [],
            "readme_content": null,
            "file_contents": {}
        },
        {
            "id": 918949363,
            "name": "Supervised-Learning",
            "full_name": "KTrigunayat/Supervised-Learning",
            "html_url": "https://github.com/KTrigunayat/Supervised-Learning",
            "description": null,
            "fork": false,
            "created_at": "2025-01-19T10:06:51Z",
            "updated_at": "2025-01-24T05:25:50Z",
            "pushed_at": "2025-01-24T05:25:47Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": "Python",
            "open_issues_count": 0,
            "license": null,
            "topics": []
        },
        {
            "id": 906128611,
            "name": "Unsupervised-Learning",
            "full_name": "KTrigunayat/Unsupervised-Learning",
            "html_url": "https://github.com/KTrigunayat/Unsupervised-Learning",
            "description": null,
            "fork": false,
            "created_at": "2024-12-20T08:18:54Z",
            "updated_at": "2025-01-07T09:31:35Z",
            "pushed_at": "2025-01-07T09:31:31Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": "HTML",
            "open_issues_count": 0,
            "license": null,
            "topics": []
        },
        {
            "id": 890716524,
            "name": "BackEnd-Development",
            "full_name": "KTrigunayat/BackEnd-Development",
            "html_url": "https://github.com/KTrigunayat/BackEnd-Development",
            "description": null,
            "fork": false,
            "created_at": "2024-11-19T03:50:32Z",
            "updated_at": "2024-12-03T07:18:00Z",
            "pushed_at": "2024-12-03T07:17:52Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": "JavaScript",
            "open_issues_count": 0,
            "license": null,
            "topics": []
        },
        {
            "id": 879506877,
            "name": "FrontEnd-Development",
            "full_name": "KTrigunayat/FrontEnd-Development",
            "html_url": "https://github.com/KTrigunayat/FrontEnd-Development",
            "description": null,
            "fork": false,
            "created_at": "2024-10-28T03:15:15Z",
            "updated_at": "2024-10-30T04:32:46Z",
            "pushed_at": "2024-11-15T10:03:10Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": "CSS",
            "open_issues_count": 0,
            "license": null,
            "topics": []
        },
        {
            "id": 874700123,
            "name": "Empevent",
            "full_name": "KTrigunayat/Empevent",
            "html_url": "https://github.com/KTrigunayat/Empevent",
            "description": null,
            "fork": false,
            "created_at": "2024-10-18T09:55:22Z",
            "updated_at": "2024-10-18T09:55:56Z",
            "pushed_at": "2024-10-18T09:55:52Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": "Python",
            "open_issues_count": 0,
            "license": null,
            "topics": []
        },
        {
            "id": 867461477,
            "name": "SQL_Kshitiz",
            "full_name": "KTrigunayat/SQL_Kshitiz",
            "html_url": "https://github.com/KTrigunayat/SQL_Kshitiz",
            "description": "Example assignments for the Databases and SQL course, 2024.",
            "fork": true,
            "created_at": "2024-10-04T05:41:13Z",
            "updated_at": "2024-10-15T03:46:29Z",
            "pushed_at": "2024-10-18T09:54:26Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": "Python",
            "open_issues_count": 0,
            "license": null,
            "topics": []
        },
        {
            "id": 867451616,
            "name": "Database-and-SQL",
            "full_name": "KTrigunayat/Database-and-SQL",
            "html_url": "https://github.com/KTrigunayat/Database-and-SQL",
            "description": null,
            "fork": false,
            "created_at": "2024-10-04T05:08:26Z",
            "updated_at": "2024-10-04T05:08:26Z",
            "pushed_at": "2024-10-04T05:08:26Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": null,
            "open_issues_count": 0,
            "license": null,
            "topics": []
        },
        {
            "id": 719006738,
            "name": "Python-project",
            "full_name": "KTrigunayat/Python-project",
            "html_url": "https://github.com/KTrigunayat/Python-project",
            "description": null,
            "fork": false,
            "created_at": "2023-11-15T08:49:55Z",
            "updated_at": "2023-11-16T05:48:15Z",
            "pushed_at": "2023-11-20T04:45:57Z",
            "stargazers_count": 0,
            "watchers_count": 0,
            "forks_count": 0,
            "language": "Python",
            "open_issues_count": 0,
            "license": null,
            "topics": []
        }
    ]
}